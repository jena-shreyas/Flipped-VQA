The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig         4) imkl/2020.1.217    7) libfabric/1.10.1
  2) gentoo/2020      5) intel/2020.1.217   8) openmpi/4.0.3
  3) gcccore/.9.3.0   6) ucx/1.8.0          9) StdEnv/2020

Lmod is automatically replacing "intel/2020.1.217" with "gcc/9.3.0".


Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/4.0.3


The following have been reloaded with a version change:
  1) python/3.8.10 => python/3.10.2


  0%|          | 0/5 [00:00<?, ?it/s][W reducer.cpp:1303] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())

  0%|          | 0/5 [17:54<?, ?it/s]
Traceback (most recent call last):
  File "train.py", line 154, in <module>
    main(args)
  File "train.py", line 130, in main
    train_stats = train_one_epoch(model, data_loader_train, optimizer, epoch, loss_scaler, args=args)
  File "/scratch/jenas/BTP/Flipped-VQA/engine.py", line 20, in train_one_epoch
    for data_iter_step, data in enumerate(metric_logger.log_every(data_loader, print_freq, header)):
  File "/scratch/jenas/BTP/Flipped-VQA/util/misc.py", line 129, in log_every
    for obj in iterable:
  File "/home/jenas/envs/flipvqa/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/home/jenas/envs/flipvqa/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/jenas/envs/flipvqa/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    return self.collate_fn(data)
  File "/scratch/jenas/BTP/Flipped-VQA/dataloader/__init__.py", line 29, in batch_collate
    vid = [batch[i]["vid"] for i in range(bs)]
  File "/scratch/jenas/BTP/Flipped-VQA/dataloader/__init__.py", line 29, in <listcomp>
    vid = [batch[i]["vid"] for i in range(bs)]
TypeError: 'NoneType' object is not subscriptable
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 104811) of binary: /home/jenas/envs/flipvqa/bin/python
Traceback (most recent call last):
  File "/home/jenas/envs/flipvqa/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/jenas/envs/flipvqa/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/home/jenas/envs/flipvqa/lib/python3.8/site-packages/torch/distributed/run.py", line 719, in main
    run(args)
  File "/home/jenas/envs/flipvqa/lib/python3.8/site-packages/torch/distributed/run.py", line 710, in run
    elastic_launch(
  File "/home/jenas/envs/flipvqa/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/jenas/envs/flipvqa/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 259, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-12-03_09:15:41
  host      : cdr2570.int.cedar.computecanada.ca
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 104811)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
